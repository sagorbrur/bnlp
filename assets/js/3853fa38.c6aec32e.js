"use strict";(self.webpackChunkbnlp=self.webpackChunkbnlp||[]).push([[808],{3154:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"archive/v1.0.0","title":"v1.0.0","description":"BNLP is a natural language processing toolkit for Bengali Language. This tool will help you to tokenize Bengali text, Embedding Bengali words, construct neural model for Bengali NLP purposes.","source":"@site/docs/11-archive/1-v1.0.0.md","sourceDirName":"11-archive","slug":"/archive/v1.0.0","permalink":"/bnlp/docs/archive/v1.0.0","draft":false,"unlisted":false,"editUrl":"https://github.com/sagorbrur/bnlp-doc/tree/main/docs/11-archive/1-v1.0.0.md","tags":[],"version":"current","lastUpdatedBy":"Ariful Alam","lastUpdatedAt":1733208715000,"sidebarPosition":1,"frontMatter":{"title":"v1.0.0","hide_title":true},"sidebar":"tutorialSidebar","previous":{"title":"Archive","permalink":"/bnlp/docs/archive"},"next":{"title":"v1.2.0","permalink":"/bnlp/docs/archive/v1.2.0"}}');var l=i(4848),r=i(8453);const s={title:"v1.0.0",hide_title:!0},o="Bengali Natural Language Processing(BNLP)",a={},d=[{value:"Installation",id:"installation",level:2},{value:"Pretrained Model",id:"pretrained-model",level:2},{value:"Tokenization",id:"tokenization",level:2},{value:"Word Embedding",id:"word-embedding",level:2},{value:"Issue",id:"issue",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"bengali-natural-language-processingbnlp",children:"Bengali Natural Language Processing(BNLP)"})}),"\n",(0,l.jsxs)(n.p,{children:["BNLP is a natural language processing toolkit for Bengali Language. This tool will help you to ",(0,l.jsx)(n.strong,{children:"tokenize Bengali text"}),", ",(0,l.jsx)(n.strong,{children:"Embedding Bengali words"}),", ",(0,l.jsx)(n.strong,{children:"construct neural model"})," for Bengali NLP purposes."]}),"\n",(0,l.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsx)(n.p,{children:"pypi package installer(python 3.6, 3.7 tested okay)"}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.code,{children:"pip install bnlp_toolkit"})}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"pretrained-model",children:"Pretrained Model"}),"\n",(0,l.jsxs)(n.p,{children:["Trained on ",(0,l.jsx)(n.code,{children:"wikipedia dump"})," dataset"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://github.com/sagorbrur/bnlp/tree/master/model",children:"Bengali SentencePiece"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://drive.google.com/open?id=13fBXPwqpP8-e_aWVognoViTeg5DxSUKR",children:"Bengali Word2Vec"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://drive.google.com/open?id=1KRA91w6dMpuQpowOwLCRplRgSdRzyOYz",children:"Bengali FastText"})}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"tokenization",children:"Tokenization"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Bengali SentencePiece Tokenization"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["tokenization using trained model","\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-py",children:'from bnlp.sentencepiece_tokenizer import SP_Tokenizer\n\nbsp = SP_Tokenizer()\nmodel_path = "./model/bn_spm.model"\ninput_text = "\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964 \u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964"\ntokens = bsp.tokenize(model_path, input_text)\nprint(tokens)\n\n'})}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["Training SentencePiece","\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-py",children:'from bnlp.sentencepiece_tokenizer import SP_Tokenizer\n\nbsp = SP_Tokenizer(is_train=True)\ndata = "test.txt"\nmodel_prefix = "test"\nvocab_size = 5\nbsp.train_bsp(data, model_prefix, vocab_size) \n\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"NLTK Tokenization"})}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-py",children:'from bnlp.nltk_tokenizer import NLTK_Tokenizer\n\ntext = "\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964 \u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964 \u09a4\u09bf\u09a8\u09bf \u0995\u09bf \u09b8\u09a4\u09cd\u09af\u09bf\u0987 \u09ad\u09be\u09b2\u09cb \u09ae\u09be\u09a8\u09c1\u09b7?"\nbnltk = NLTK_Tokenizer(text)\nword_tokens = bnltk.word_tokenize()\nsentence_tokens = bnltk.sentence_tokenize()\nprint(word_tokens)\nprint(sentence_tokens)\n\n'})}),"\n",(0,l.jsx)(n.h2,{id:"word-embedding",children:"Word Embedding"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Bengali Word2Vec"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsx)(n.p,{children:"Generate Vector using pretrain model"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-py",children:"from bnlp.bengali_word2vec import Bengali_Word2Vec\n\nbwv = Bengali_Word2Vec()\nmodel_path = \"model/wiki.bn.text.model\"\nword = '\u0986\u09ae\u09be\u09b0'\nvector = bwv.generate_word_vector(model_path, word)\nprint(vector.shape)\nprint(vector)\n\n"})}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsx)(n.p,{children:"Find Most Similar Word Using Pretrained Model"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-py",children:"from bnlp.bengali_word2vec import Bengali_Word2Vec\n\nbwv = Bengali_Word2Vec()\nmodel_path = \"model/wiki.bn.text.model\"\nword = '\u0986\u09ae\u09be\u09b0'\nsimilar = bwv.most_similar(model_path, word)\nprint(similar)\n\n"})}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsx)(n.p,{children:"Train Bengali Word2Vec with your own data"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-py",children:'from bnlp.bengali_word2vec import Bengali_Word2Vec\n\ndata_file = "test.txt"\nmodel_name = "test_model.model"\nvector_name = "test_vector.vector"\nbwv.train_word2vec(data_file, model_name, vector_name)\n\n\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Bengali FastText"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:["Download Bengali FastText Pretrained Model From ",(0,l.jsx)(n.a,{href:"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.bn.300.bin.gz",children:"Here"})]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsx)(n.p,{children:"Generate Vector Using Pretrained Model"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-py",children:'from bnlp.bengali_fasttext import Bengali_Fasttext\n\nbft = Bengali_Fasttext()\nword = "\u0997\u09cd\u09b0\u09be\u09ae"\nmodel_path = "cc.bn.300.bin"\nword_vector = bft.generate_word_vector(model_path, word)\nprint(word_vector.shape)\nprint(word_vector)\n\n\n'})}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsx)(n.p,{children:"Train Bengali FastText Model"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-py",children:'from bnlp.bengali_fasttext import Bengali_Fasttext\n\nbft = Bengali_Fasttext(is_train=True)\ndata = "data.txt"\nmodel_name = "saved_model.bin"\nbft.train_fasttext(data, model_name)\n\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"issue",children:"Issue"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["if ",(0,l.jsx)(n.code,{children:"ModuleNotFoundError: No module named 'fasttext'"})," problem arise please do the next line"]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.code,{children:"pip install fasttext"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:["if ",(0,l.jsx)(n.code,{children:"nltk"})," issue arise please do the following line before importing ",(0,l.jsx)(n.code,{children:"bnlp"})]}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-py",children:'import nltk\nnltk.download("punkt")\n'})})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>o});var t=i(6540);const l={},r=t.createContext(l);function s(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:s(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);