"use strict";(self.webpackChunkbnlp=self.webpackChunkbnlp||[]).push([[554],{8122:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>m,frontMatter:()=>i,metadata:()=>r,toc:()=>s});const r=JSON.parse('{"id":"word-embedding","title":"Word Embedding","description":"Bengali Word2Vec","source":"@site/docs/5-word-embedding.md","sourceDirName":".","slug":"/word-embedding","permalink":"/bnlp/docs/word-embedding","draft":false,"unlisted":false,"editUrl":"https://github.com/sagorbrur/bnlp-doc/tree/main/docs/5-word-embedding.md","tags":[],"version":"current","lastUpdatedBy":"Ariful Alam","lastUpdatedAt":1733130906000,"sidebarPosition":5,"frontMatter":{"id":"word-embedding","title":"Word Embedding"},"sidebar":"tutorialSidebar","previous":{"title":"Tokenization","permalink":"/bnlp/docs/tokenization"},"next":{"title":"Document Embedding","permalink":"/bnlp/docs/document-embedding"}}');var o=t(4848),d=t(8453);const i={id:"word-embedding",title:"Word Embedding"},a=void 0,l={},s=[{value:"Bengali Word2Vec",id:"bengali-word2vec",level:2},{value:"Generate Vector Using Pretrain Model",id:"generate-vector-using-pretrain-model",level:3},{value:"Find Most Similar Word Using Pretrained Model",id:"find-most-similar-word-using-pretrained-model",level:3},{value:"Generate Vector Using Own Model",id:"generate-vector-using-own-model",level:3},{value:"Find Most Similar Word Using Own Model",id:"find-most-similar-word-using-own-model",level:3},{value:"Train Bengali Word2Vec with your own data",id:"train-bengali-word2vec-with-your-own-data",level:3},{value:"Pre-train or resume word2vec training with same or new corpus or tokenized sentences",id:"pre-train-or-resume-word2vec-training-with-same-or-new-corpus-or-tokenized-sentences",level:3},{value:"Bengali FastText",id:"bengali-fasttext",level:2},{value:"Generate Vector Using Pretrained Model",id:"generate-vector-using-pretrained-model",level:3},{value:"Generate Vector File from Fasttext Binary Model",id:"generate-vector-file-from-fasttext-binary-model",level:3},{value:"Generate Vector Using Pretrained Model",id:"generate-vector-using-pretrained-model-1",level:3},{value:"Generate Vector File from Fasttext Binary Model",id:"generate-vector-file-from-fasttext-binary-model-1",level:3},{value:"Train Bengali FastText Model",id:"train-bengali-fasttext-model",level:3},{value:"Bengali GloVe Word Vectors",id:"bengali-glove-word-vectors",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,d.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"bengali-word2vec",children:"Bengali Word2Vec"}),"\n",(0,o.jsx)(n.h3,{id:"generate-vector-using-pretrain-model",children:"Generate Vector Using Pretrain Model"}),"\n",(0,o.jsxs)(n.p,{children:["To use pretrained model do not pass ",(0,o.jsx)(n.code,{children:"model_path"})," to ",(0,o.jsx)(n.code,{children:"BengaliWord2Vec()"}),". It will download pretrained ",(0,o.jsx)(n.code,{children:"BengaliWord2Vec"})," model itself."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:"from bnlp import BengaliWord2Vec\n\nbwv = BengaliWord2Vec()\n\nword = '\u0997\u09cd\u09b0\u09be\u09ae'\nvector = bwv.get_word_vector(word)\nprint(vector.shape)\n"})}),"\n",(0,o.jsx)(n.h3,{id:"find-most-similar-word-using-pretrained-model",children:"Find Most Similar Word Using Pretrained Model"}),"\n",(0,o.jsxs)(n.p,{children:["To use pretrained model do not pass ",(0,o.jsx)(n.code,{children:"model_path"})," to ",(0,o.jsx)(n.code,{children:"BengaliWord2Vec()"}),". It will download pretrained ",(0,o.jsx)(n.code,{children:"BengaliWord2Vec"})," model itself."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:"from bnlp import BengaliWord2Vec\n\nbwv = BengaliWord2Vec()\n\nword = '\u0997\u09cd\u09b0\u09be\u09ae'\nsimilar_words = bwv.get_most_similar_words(word, topn=10)\nprint(similar_words)\n"})}),"\n",(0,o.jsx)(n.h3,{id:"generate-vector-using-own-model",children:"Generate Vector Using Own Model"}),"\n",(0,o.jsxs)(n.p,{children:["To use own model pass model path as ",(0,o.jsx)(n.code,{children:"model_path"})," argument to ",(0,o.jsx)(n.code,{children:"BengaliWord2Vec()"})," like below snippet"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:"from bnlp import BengaliWord2Vec\n\nown_model_path = \"own_directory/own_bwv_model.pkl\"\nbwv = BengaliWord2Vec(model_path=own_model_path)\n\nword = '\u0997\u09cd\u09b0\u09be\u09ae'\nvector = bwv.get_word_vector(word)\nprint(vector.shape)\n"})}),"\n",(0,o.jsx)(n.h3,{id:"find-most-similar-word-using-own-model",children:"Find Most Similar Word Using Own Model"}),"\n",(0,o.jsxs)(n.p,{children:["To use own model pass model path as ",(0,o.jsx)(n.code,{children:"model_path"})," argument to ",(0,o.jsx)(n.code,{children:"BengaliWord2Vec()"})," like below snippet"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:"from bnlp import BengaliWord2Vec\n\nown_model_path = \"own_directory/own_bwv_model.pkl\"\nbwv = BengaliWord2Vec(model_path=own_model_path)\n\nword = '\u0997\u09cd\u09b0\u09be\u09ae'\nsimilar_words = bwv.get_most_similar_words(word, topn=10)\nprint(similar_words)\n"})}),"\n",(0,o.jsx)(n.h3,{id:"train-bengali-word2vec-with-your-own-data",children:"Train Bengali Word2Vec with your own data"}),"\n",(0,o.jsx)(n.p,{children:"Train Bengali word2vec with your custom raw data or tokenized sentences."}),"\n",(0,o.jsx)(n.p,{children:"Custom tokenized sentence format example:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:"sentences = [['\u0986\u09ae\u09bf', '\u09ad\u09be\u09a4', '\u0996\u09be\u0987', '\u0964'], ['\u09b8\u09c7', '\u09ac\u09be\u099c\u09be\u09b0\u09c7', '\u09af\u09be\u09df', '\u0964']]\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Check ",(0,o.jsx)(n.a,{href:"https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec",children:"gensim word2vec api"})," for details of training parameter"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:'from bnlp import Word2VecTraining\n\ntrainer = Word2VecTraining()\n\ndata_file = "raw_text.txt" # or you can pass custom sentence tokens as list of list\nmodel_name = "test_model.model"\nvector_name = "test_vector.vector"\ntrainer.train(data_file, model_name, vector_name, epochs=5)\n'})}),"\n",(0,o.jsx)(n.h3,{id:"pre-train-or-resume-word2vec-training-with-same-or-new-corpus-or-tokenized-sentences",children:"Pre-train or resume word2vec training with same or new corpus or tokenized sentences"}),"\n",(0,o.jsxs)(n.p,{children:["Check ",(0,o.jsx)(n.a,{href:"https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec",children:"gensim word2vec api"})," for details of training parameter"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:'from bnlp import Word2VecTraining\n\ntrainer = Word2VecTraining()\n\ntrained_model_path = "mytrained_model.model"\ndata_file = "raw_text.txt"\nmodel_name = "test_model.model"\nvector_name = "test_vector.vector"\ntrainer.pretrain(trained_model_path, data_file, model_name, vector_name, epochs=5)\n'})}),"\n",(0,o.jsx)(n.h2,{id:"bengali-fasttext",children:"Bengali FastText"}),"\n",(0,o.jsxs)(n.p,{children:["To use ",(0,o.jsx)(n.code,{children:"fasttext"})," you need to install fasttext manually by ",(0,o.jsx)(n.code,{children:"pip install fasttext==0.9.2"})," or install via bnlp by ",(0,o.jsx)(n.code,{children:"pip install bnlp_toolkit[fasttext]"})]}),"\n",(0,o.jsxs)(n.p,{children:["NB: To use ",(0,o.jsx)(n.code,{children:"fasttext"})," on ",(0,o.jsx)(n.code,{children:"windows"}),", install ",(0,o.jsx)(n.code,{children:"fasttext"})," by following ",(0,o.jsx)(n.a,{href:"https://medium.com/@oleg.tarasov/building-fasttext-python-wrapper-from-source-under-windows-68e693a68cbb",children:"this article"}),"."]}),"\n",(0,o.jsx)(n.h3,{id:"generate-vector-using-pretrained-model",children:"Generate Vector Using Pretrained Model"}),"\n",(0,o.jsxs)(n.p,{children:["To use pretrained model do not pass ",(0,o.jsx)(n.code,{children:"model_path"})," to ",(0,o.jsx)(n.code,{children:"BengaliFasttext()"}),". It will download pretrained ",(0,o.jsx)(n.code,{children:"BengaliFasttext"})," model itself."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:'from bnlp.embedding.fasttext import BengaliFasttext\n\nbft = BengaliFasttext()\n\nword = "\u0997\u09cd\u09b0\u09be\u09ae"\nword_vector = bft.get_word_vector(word)\nprint(word_vector.shape)\n'})}),"\n",(0,o.jsx)(n.h3,{id:"generate-vector-file-from-fasttext-binary-model",children:"Generate Vector File from Fasttext Binary Model"}),"\n",(0,o.jsxs)(n.p,{children:["To use pretrained model do not pass ",(0,o.jsx)(n.code,{children:"model_path"})," to ",(0,o.jsx)(n.code,{children:"BengaliFasttext()"}),". It will download pretrained ",(0,o.jsx)(n.code,{children:"BengaliFasttext"})," model itself."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:'from bnlp.embedding.fasttext import BengaliFasttext\n\nbft = BengaliFasttext()\n\nout_vector_name = "myvector.txt"\nbft.bin2vec(out_vector_name)\n'})}),"\n",(0,o.jsx)(n.h3,{id:"generate-vector-using-pretrained-model-1",children:"Generate Vector Using Pretrained Model"}),"\n",(0,o.jsxs)(n.p,{children:["To use own model pass model path as ",(0,o.jsx)(n.code,{children:"model_path"})," argument to ",(0,o.jsx)(n.code,{children:"BengaliFasttext()"})," like below snippet."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:'from bnlp.embedding.fasttext import BengaliFasttext\n\nown_model_path = "own_directory/own_fasttext_model.bin"\nbft = BengaliFasttext(model_path=own_model_path)\n\nword = "\u0997\u09cd\u09b0\u09be\u09ae"\nword_vector = bft.get_word_vector(model_path, word)\nprint(word_vector.shape)\n'})}),"\n",(0,o.jsx)(n.h3,{id:"generate-vector-file-from-fasttext-binary-model-1",children:"Generate Vector File from Fasttext Binary Model"}),"\n",(0,o.jsxs)(n.p,{children:["To use own model pass model path as ",(0,o.jsx)(n.code,{children:"model_path"})," argument to ",(0,o.jsx)(n.code,{children:"BengaliFasttext()"})," like below snippet."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:'from bnlp.embedding.fasttext import BengaliFasttext\n\nown_model_path = "own_directory/own_fasttext_model.bin"\nbft = BengaliFasttext(model_path=own_model_path)\n\nout_vector_name = "myvector.txt"\nbft.bin2vec(out_vector_name)\n'})}),"\n",(0,o.jsx)(n.h3,{id:"train-bengali-fasttext-model",children:"Train Bengali FastText Model"}),"\n",(0,o.jsxs)(n.p,{children:["Check ",(0,o.jsx)(n.a,{href:"https://fasttext.cc/docs/en/options.html",children:"fasttext documentation"})," for details of training parameter"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:'from bnlp.embedding.fasttext import FasttextTrainer\n\ntrainer = FasttextTrainer()\n\ndata = "raw_text.txt"\nmodel_name = "saved_model.bin"\nepoch = 50\ntrainer.train(data, model_name, epoch)\n'})}),"\n",(0,o.jsx)(n.h2,{id:"bengali-glove-word-vectors",children:"Bengali GloVe Word Vectors"}),"\n",(0,o.jsxs)(n.p,{children:["We trained glove model with bengali data(wiki+news articles) and published bengali glove word vectors",(0,o.jsx)("br",{}),"\nYou can download and use it on your different machine learning purposes."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-py",children:'from bnlp import BengaliGlove\n\nbengali_glove = BengaliGlove() # will automatically download pretrained model\n\nword = "\u0997\u09cd\u09b0\u09be\u09ae"\nvector = bengali_glove.get_word_vector(word)\nprint(vector.shape)\n\nsimilar_words = bengali_glove.get_closest_word(word)\nprint(similar_words)\n'})})]})}function m(e={}){const{wrapper:n}={...(0,d.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>a});var r=t(6540);const o={},d=r.createContext(o);function i(e){const n=r.useContext(d);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),r.createElement(d.Provider,{value:n},e.children)}}}]);