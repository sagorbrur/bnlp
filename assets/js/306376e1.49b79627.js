"use strict";(self.webpackChunkbnlp=self.webpackChunkbnlp||[]).push([[706],{3095:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>d});const l=JSON.parse('{"id":"archive/v2.3.0","title":"v2.3.0","description":"BNLP is a natural language processing toolkit for Bengali Language. This tool will help you to tokenize Bengali text, Embedding Bengali words, Bengali POS Tagging, Bengali Name Entity Recognition, Construct Neural Model for Bengali NLP purposes.","source":"@site/docs/11-archive/3-v2.3.0.md","sourceDirName":"11-archive","slug":"/archive/v2.3.0","permalink":"/bnlp/docs/archive/v2.3.0","draft":false,"unlisted":false,"editUrl":"https://github.com/sagorbrur/bnlp-doc/tree/main/docs/11-archive/3-v2.3.0.md","tags":[],"version":"current","lastUpdatedBy":"Ariful Alam","lastUpdatedAt":1733208908000,"sidebarPosition":3,"frontMatter":{"title":"v2.3.0","hide_title":true},"sidebar":"tutorialSidebar","previous":{"title":"v1.2.0","permalink":"/bnlp/docs/archive/v1.2.0"},"next":{"title":"v3.3.2","permalink":"/bnlp/docs/archive/v3.3.2"}}');var r=i(4848),t=i(8453);const s={title:"v2.3.0",hide_title:!0},a="Bengali Natural Language Processing(BNLP)",o={},d=[{value:"Current Features",id:"current-features",level:2},{value:"Installation",id:"installation",level:2},{value:"PIP installer(python 3.5, 3.6, 3.7 tested okay)",id:"pip-installerpython-35-36-37-tested-okay",level:3},{value:"Local Installer",id:"local-installer",level:3},{value:"Pretrained Model",id:"pretrained-model",level:2},{value:"Download Link",id:"download-link",level:3},{value:"Training Details",id:"training-details",level:3},{value:"Tokenization",id:"tokenization",level:2},{value:"Word Embedding",id:"word-embedding",level:2},{value:"Bengali POS Tagging",id:"bengali-pos-tagging",level:2},{value:"Bengali NER",id:"bengali-ner",level:2},{value:"Issue",id:"issue",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"bengali-natural-language-processingbnlp",children:"Bengali Natural Language Processing(BNLP)"})}),"\n",(0,r.jsxs)(n.p,{children:["BNLP is a natural language processing toolkit for Bengali Language. This tool will help you to ",(0,r.jsx)(n.strong,{children:"tokenize Bengali text"}),", ",(0,r.jsx)(n.strong,{children:"Embedding Bengali words"}),", ",(0,r.jsx)(n.strong,{children:"Bengali POS Tagging"}),", ",(0,r.jsx)(n.strong,{children:"Bengali Name Entity Recognition"}),", ",(0,r.jsx)(n.strong,{children:"Construct Neural Model"})," for Bengali NLP purposes."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"NB: Any Researcher who refer this tool in his/her paper please let us know, we will include paper link here"}),(0,r.jsx)("br",{})]}),"\n",(0,r.jsx)(n.h2,{id:"current-features",children:"Current Features"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"#tokenization",children:"Bengali Tokenization"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"SentencePiece Tokenizer"}),"\n",(0,r.jsx)(n.li,{children:"Basic Tokenizer"}),"\n",(0,r.jsx)(n.li,{children:"NLTK Tokenizer"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"#word-embedding",children:"Bengali Word Embedding"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Bengali Word2Vec"}),"\n",(0,r.jsx)(n.li,{children:"Bengali Fasttext"}),"\n",(0,r.jsx)(n.li,{children:"Bengali GloVe"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#bengali-pos-tagging",children:"Bengali POS Tagging"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#bengali-ner",children:"Bengali Name Entity Recognition"})}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,r.jsx)(n.h3,{id:"pip-installerpython-35-36-37-tested-okay",children:"PIP installer(python 3.5, 3.6, 3.7 tested okay)"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:"pip install bnlp_toolkit"})}),"\n",(0,r.jsx)(n.h3,{id:"local-installer",children:"Local Installer"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"$git clone https://github.com/sagorbrur/bnlp.git\n$cd bnlp\n$python setup.py install\n"})}),"\n",(0,r.jsx)(n.h2,{id:"pretrained-model",children:"Pretrained Model"}),"\n",(0,r.jsx)(n.h3,{id:"download-link",children:"Download Link"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/sagorbrur/bnlp/tree/master/model",children:"Bengali SentencePiece"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://drive.google.com/open?id=1DxR8Vw61zRxuUm17jzFnOX97j7QtNW7U",children:"Bengali Word2Vec"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://drive.google.com/open?id=1CFA-SluRyz3s5gmGScsFUcs7AjLfscm2",children:"Bengali FastText"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/sagorbrur/GloVe-Bengali",children:"Bengali GloVe Wordvectors"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/sagorbrur/bnlp/blob/master/model/bn_pos.pkl",children:"Bengali POS Tag model"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/sagorbrur/bnlp/blob/master/model/bn_ner.pkl",children:"Bengali NER model"})}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"training-details",children:"Training Details"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Sentencepiece, Word2Vec, Fasttext, GloVe model trained with ",(0,r.jsx)(n.strong,{children:"Bengali Wikipedia Dump Dataset"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://dumps.wikimedia.org/bnwiki/latest/",children:"Bengali Wiki Dump"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"SentencePiece Training Vocab Size=50000"}),"\n",(0,r.jsx)(n.li,{children:"Fasttext trained with total words = 20M, vocab size = 1171011, epoch=50, embedding dimension = 300 and the training loss = 0.318668,"}),"\n",(0,r.jsx)(n.li,{children:"Word2Vec word embedding dimension = 300"}),"\n",(0,r.jsxs)(n.li,{children:["To Know Bengali GloVe Wordvector and training process follow ",(0,r.jsx)(n.a,{href:"https://github.com/sagorbrur/GloVe-Bengali",children:"this"})," repository"]}),"\n",(0,r.jsxs)(n.li,{children:["Bengali CRF POS Tagging was training with ",(0,r.jsx)(n.a,{href:"https://github.com/abhishekgupta92/bangla_pos_tagger/tree/master/data",children:"nltr"})," dataset with 80% accuracy."]}),"\n",(0,r.jsxs)(n.li,{children:["Bengali CRF NER Tagging was train with ",(0,r.jsx)(n.a,{href:"https://github.com/MISabic/NER-Bangla-Dataset",children:"this"})," data with 90% accuracy."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"tokenization",children:"Tokenization"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Bengali SentencePiece Tokenization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["tokenization using trained model","\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'from bnlp.sentencepiece_tokenizer import SP_Tokenizer\n\nbsp = SP_Tokenizer()\nmodel_path = "./model/bn_spm.model"\ninput_text = "\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964 \u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964"\ntokens = bsp.tokenize(model_path, input_text)\nprint(tokens)\ntext2id = bsp.text2id(model_path, input_text)\nprint(text2id)\nid2text = bsp.id2text(model_path, text2id)\nprint(id2text)\n\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Training SentencePiece","\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'from bnlp.sentencepiece_tokenizer import SP_Tokenizer\n\nbsp = SP_Tokenizer()\ndata = "test.txt"\nmodel_prefix = "test"\nvocab_size = 5\nbsp.train_bsp(data, model_prefix, vocab_size) \n\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Basic Tokenizer"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'from bnlp.basic_tokenizer import BasicTokenizer\nbasic_t = BasicTokenizer()\nraw_text = "\u0986\u09ae\u09bf \u09ac\u09be\u0982\u09b2\u09be\u09df \u0997\u09be\u09a8 \u0997\u09be\u0987\u0964"\ntokens = basic_t.tokenize(raw_text)\nprint(tokens)\n\n# output: ["\u0986\u09ae\u09bf", "\u09ac\u09be\u0982\u09b2\u09be\u09df", "\u0997\u09be\u09a8", "\u0997\u09be\u0987", "\u0964"]\n\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"NLTK Tokenization"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'from bnlp.nltk_tokenizer import NLTK_Tokenizer\n\ntext = "\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964 \u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964 \u09a4\u09bf\u09a8\u09bf \u0995\u09bf \u09b8\u09a4\u09cd\u09af\u09bf\u0987 \u09ad\u09be\u09b2\u09cb \u09ae\u09be\u09a8\u09c1\u09b7?"\nbnltk = NLTK_Tokenizer()\nword_tokens = bnltk.word_tokenize(text)\nsentence_tokens = bnltk.sentence_tokenize(text)\nprint(word_tokens)\nprint(sentence_tokens)\n\n# output\n# word_token: ["\u0986\u09ae\u09bf", "\u09ad\u09be\u09a4", "\u0996\u09be\u0987", "\u0964", "\u09b8\u09c7", "\u09ac\u09be\u099c\u09be\u09b0\u09c7", "\u09af\u09be\u09df", "\u0964", "\u09a4\u09bf\u09a8\u09bf", "\u0995\u09bf", "\u09b8\u09a4\u09cd\u09af\u09bf\u0987", "\u09ad\u09be\u09b2\u09cb", "\u09ae\u09be\u09a8\u09c1\u09b7", "?"]\n# sentence_token: ["\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964", "\u09b8\u09c7 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u09af\u09be\u09df\u0964", "\u09a4\u09bf\u09a8\u09bf \u0995\u09bf \u09b8\u09a4\u09cd\u09af\u09bf\u0987 \u09ad\u09be\u09b2\u09cb \u09ae\u09be\u09a8\u09c1\u09b7?"]\n\n'})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"word-embedding",children:"Word Embedding"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Bengali Word2Vec"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Generate Vector using pretrain model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"from bnlp.bengali_word2vec import Bengali_Word2Vec\n\nbwv = Bengali_Word2Vec()\nmodel_path = \"model/bengali_word2vec.model\"\nword = '\u0986\u09ae\u09be\u09b0'\nvector = bwv.generate_word_vector(model_path, word)\nprint(vector.shape)\nprint(vector)\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Find Most Similar Word Using Pretrained Model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"from bnlp.bengali_word2vec import Bengali_Word2Vec\n\nbwv = Bengali_Word2Vec()\nmodel_path = \"model/bengali_word2vec.model\"\nword = '\u0986\u09ae\u09be\u09b0'\nsimilar = bwv.most_similar(model_path, word)\nprint(similar)\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Train Bengali Word2Vec with your own data"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'from bnlp.bengali_word2vec import Bengali_Word2Vec\nbwv = Bengali_Word2Vec(True)\ndata_file = "test.txt"\nmodel_name = "test_model.model"\nvector_name = "test_vector.vector"\nbwv.train_word2vec(data_file, model_name, vector_name)\n\n\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Bengali FastText"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Generate Vector Using Pretrained Model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'from bnlp.bengali_fasttext import Bengali_Fasttext\n\nbft = Bengali_Fasttext()\nword = "\u0997\u09cd\u09b0\u09be\u09ae"\nmodel_path = "model/bengali_fasttext.bin"\nword_vector = bft.generate_word_vector(model_path, word)\nprint(word_vector.shape)\nprint(word_vector)\n\n\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Train Bengali FastText Model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'from bnlp.bengali_fasttext import Bengali_Fasttext\n\nbft = Bengali_Fasttext()\ndata = "data.txt"\nmodel_name = "saved_model.bin"\nepoch = 50\nbft.train_fasttext(data, model_name, epoch)\n'})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Bengali GloVe Word Vectors"})}),"\n",(0,r.jsxs)(n.p,{children:["We trained glove model with bengali data(wiki+news articles) and published bengali glove word vectors",(0,r.jsx)("br",{}),"\nYou can download and use it on your different machine learning purposes."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'from bnlp.glove_wordvector import BN_Glove\nglove_path = "bn_glove.39M.100d.txt"\nword = "\u0997\u09cd\u09b0\u09be\u09ae"\nbng = BN_Glove()\nres = bng.closest_word(glove_path, word)\nprint(res)\nvec = bng.word2vec(glove_path, word)\nprint(vec)\n\n'})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"bengali-pos-tagging",children:"Bengali POS Tagging"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Bengali CRF POS Tagging"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Find Pos Tag Using Pretrained Model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"from bnlp.pos import POS\nbn_pos = POS()\nmodel_path = \"model/bn_pos.pkl\"\ntext = \"\u0986\u09ae\u09bf \u09ad\u09be\u09a4 \u0996\u09be\u0987\u0964\"\nres = bn_pos.tag(model_path, text)\nprint(res)\n# [('\u0986\u09ae\u09bf', 'PPR'), ('\u09ad\u09be\u09a4', 'NC'), ('\u0996\u09be\u0987', 'VM'), ('\u0964', 'PU')]\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Train POS Tag Model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"from bnlp.pos import POS\nbn_pos = POS()\nmodel_name = \"pos_model.pkl\"\ntagged_sentences = [[('\u09b0\u09aa\u09cd\u09a4\u09be\u09a8\u09bf', 'JJ'), ('\u09a6\u09cd\u09b0\u09ac\u09cd\u09af', 'NC'), ('-', 'PU'), ('\u09a4\u09be\u099c\u09be', 'JJ'), ('\u0993', 'CCD'), ('\u09b6\u09c1\u0995\u09a8\u09be', 'JJ'), ('\u09ab\u09b2', 'NC'), (',', 'PU'), ('\u0986\u09ab\u09bf\u09ae', 'NC'), (',', 'PU'), ('\u09aa\u09b6\u09c1\u099a\u09b0\u09cd\u09ae', 'NC'), ('\u0993', 'CCD'), ('\u09aa\u09b6\u09ae', 'NC'), ('\u098f\u09ac\u0982', 'CCD'),('\u0995\u09be\u09b0\u09cd\u09aa\u09c7\u099f', 'NC'), ('\u09f7', 'PU')], [('\u09ae\u09be\u099f\u09bf', 'NC'), ('\u09a5\u09c7\u0995\u09c7', 'PP'), ('\u09ac\u09dc\u099c\u09cb\u09b0', 'JQ'), ('\u099a\u09be\u09b0', 'JQ'), ('\u09aa\u09be\u0981\u099a', 'JQ'), ('\u09ab\u09c1\u099f', 'CCL'), ('\u0989\u0981\u099a\u09c1', 'JJ'), ('\u09b9\u09ac\u09c7', 'VM'), ('\u09f7', 'PU')]]\n\nbn_pos.train(model_name, tagged_sentences)\n\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"bengali-ner",children:"Bengali NER"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Bengali CRF NER"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Find NER Tag Using Pretrained Model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"from bnlp.ner import NER\nbn_ner = NER()\nmodel_path = \"model/bn_ner.pkl\"\ntext = \"\u09b8\u09c7 \u09a2\u09be\u0995\u09be\u09df \u09a5\u09be\u0995\u09c7\u0964\"\nresult = bn_ner.tag(model_path, text)\nprint(result)\n# [('\u09b8\u09c7', 'O'), ('\u09a2\u09be\u0995\u09be\u09df', 'S-LOC'), ('\u09a5\u09be\u0995\u09c7', 'O')]\n\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Train NER Tag Model"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"from bnlp.ner import NER\nbn_ner = NER()\nmodel_name = \"ner_model.pkl\"\ntagged_sentences = [[('\u09a4\u09cd\u09b0\u09be\u09a3', 'O'),('\u0993', 'O'),('\u09b8\u09ae\u09be\u099c\u0995\u09b2\u09cd\u09af\u09be\u09a3', 'O'),('\u09b8\u09ae\u09cd\u09aa\u09be\u09a6\u0995', 'S-PER'),('\u09b8\u09c1\u099c\u09bf\u09a4', 'B-PER'),('\u09b0\u09be\u09df', 'I-PER'),('\u09a8\u09a8\u09cd\u09a6\u09c0', 'E-PER'),('\u09aa\u09cd\u09b0\u09ae\u09c1\u0996', 'O'),('\u09b8\u0982\u09ac\u09be\u09a6', 'O'),('\u09b8\u09ae\u09cd\u09ae\u09c7\u09b2\u09a8\u09c7', 'O'),('\u0989\u09aa\u09b8\u09cd\u09a5\u09bf\u09a4', 'O'),('\u099b\u09bf\u09b2\u09c7\u09a8', 'O')], [('\u09a4\u09cd\u09b0\u09be\u09a3', 'O'),('\u0993', 'O'),('\u09b8\u09ae\u09be\u099c\u0995\u09b2\u09cd\u09af\u09be\u09a3', 'O'),('\u09b8\u09ae\u09cd\u09aa\u09be\u09a6\u0995', 'S-PER'),('\u09b8\u09c1\u099c\u09bf\u09a4', 'B-PER'),('\u09b0\u09be\u09df', 'I-PER'),('\u09a8\u09a8\u09cd\u09a6\u09c0', 'E-PER'),('\u09aa\u09cd\u09b0\u09ae\u09c1\u0996', 'O'),('\u09b8\u0982\u09ac\u09be\u09a6', 'O'),('\u09b8\u09ae\u09cd\u09ae\u09c7\u09b2\u09a8\u09c7', 'O'),('\u0989\u09aa\u09b8\u09cd\u09a5\u09bf\u09a4', 'O'),('\u099b\u09bf\u09b2\u09c7\u09a8', 'O')], [('\u09a4\u09cd\u09b0\u09be\u09a3', 'O'),('\u0993', 'O'),('\u09b8\u09ae\u09be\u099c\u0995\u09b2\u09cd\u09af\u09be\u09a3', 'O'),('\u09b8\u09ae\u09cd\u09aa\u09be\u09a6\u0995', 'S-PER'),('\u09b8\u09c1\u099c\u09bf\u09a4', 'B-PER'),('\u09b0\u09be\u09df', 'I-PER'),('\u09a8\u09a8\u09cd\u09a6\u09c0', 'E-PER'),('\u09aa\u09cd\u09b0\u09ae\u09c1\u0996', 'O'),('\u09b8\u0982\u09ac\u09be\u09a6', 'O'),('\u09b8\u09ae\u09cd\u09ae\u09c7\u09b2\u09a8\u09c7', 'O'),('\u0989\u09aa\u09b8\u09cd\u09a5\u09bf\u09a4', 'O'),('\u099b\u09bf\u09b2\u09c7\u09a8', 'O')]]\n\nbn_ner.train(model_name, tagged_sentences)\n\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"issue",children:"Issue"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["if ",(0,r.jsx)(n.code,{children:"ModuleNotFoundError: No module named 'fasttext'"})," problem arise please do the next line"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:"pip install fasttext"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["if ",(0,r.jsx)(n.code,{children:"nltk"})," issue arise please do the following line before importing ",(0,r.jsx)(n.code,{children:"bnlp"})]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:'import nltk\nnltk.download("punkt")\n'})})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>a});var l=i(6540);const r={},t=l.createContext(r);function s(e){const n=l.useContext(t);return l.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),l.createElement(t.Provider,{value:n},e.children)}}}]);